{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0291c07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Dinesh\n",
      "[nltk_data]     Reddy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Dinesh\n",
      "[nltk_data]     Reddy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Dinesh Reddy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Dinesh\n",
      "[nltk_data]     Reddy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n– Hate and Offensive(HOF)\\n– Not Hate and Offensive(NOT)\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from nltk.util import pr\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "\"\"\"Hate Speech(HATE)\n",
    "– Offensive(OFFN)\n",
    "– Profane(PRFN)\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "– Hate and Offensive(HOF)\n",
    "– Not Hate and Offensive(NOT)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d71c0a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDinesh Reddy\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mhindi_dataset.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel(r\"C:\\Users\\Dinesh Reddy\\Desktop\\hindi_dataset.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b261ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4aca91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def remove_english_letters(text):\n",
    "    # Regular expression to match English letters\n",
    "    english_pattern = re.compile(r'[a-zA-Z]')\n",
    "    \n",
    "    # Replace English letters with an empty string\n",
    "    return re.sub(english_pattern, '', text)\n",
    "\n",
    "# Apply the remove_english_letters function to the desired column(s)\n",
    "data['text'] = data['text'].apply(remove_english_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6751a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c1b4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel(\"new_sheet.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5baabcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a0e260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09302f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Read the existing Excel file into a DataFrame\n",
    "file_path = r\"C:\\Users\\Dinesh Reddy\\Desktop\\new_sheet.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Clean the text by removing symbols\n",
    "cleaned_text = df[\"text\"].apply(lambda x: re.sub(r'[^\\w\\s]', '', str(x)))\n",
    "\n",
    "# Add the cleaned text as a new column in the DataFrame\n",
    "df[\"Cleaned Text\"] = cleaned_text\n",
    "    \n",
    "\n",
    "# Save the DataFrame to a new Excel file\n",
    "output_file_path = r\"C:\\Users\\Dinesh Reddy\\Desktop\\outputd.xlsx\"\n",
    "df.to_excel(output_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8a20d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=pd.read_excel(output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "864f9bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>task_1</th>\n",
       "      <th>task_2</th>\n",
       "      <th>task_3</th>\n",
       "      <th>Cleaned Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hasoc_hi_5556</td>\n",
       "      <td>बांग्लादेश की शानदार वापसी, भारत को 314 रन पर ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>बगलदश क शनदर वपस भरत क 314 रन पर रक  19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hasoc_hi_5648</td>\n",
       "      <td>सब रंडी नाच देखने मे व्यस्त जैसे ही कोई #शांती...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>PRFN</td>\n",
       "      <td>UNT</td>\n",
       "      <td>सब रड नच दखन म वयसत जस ह कई शतदत क सथ कछ हग सब...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hasoc_hi_164</td>\n",
       "      <td>तुम जैसे हरामियों के लिए बस जूतों की कमी है शु...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>PRFN</td>\n",
       "      <td>TIN</td>\n",
       "      <td>तम जस हरमय क लए बस जत क कम ह शकर कर अभ तमहर लच...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hasoc_hi_3530</td>\n",
       "      <td>बीजेपी  आकाश विजयवर्गीय जेल से रिहा, जमानत मिल...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>बजप  आकश वजयवरगय जल स रह जमनत मलन क खश म एक सम...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hasoc_hi_5206</td>\n",
       "      <td>चमकी बुखार: विधानसभा परिसर में आरजेडी का प्रदर...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>चमक बखर वधनसभ परसर म आरजड क परदरशन तजसव यदव नद...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         text_id                                               text task_1  \\\n",
       "0  hasoc_hi_5556  बांग्लादेश की शानदार वापसी, भारत को 314 रन पर ...    NOT   \n",
       "1  hasoc_hi_5648  सब रंडी नाच देखने मे व्यस्त जैसे ही कोई #शांती...    HOF   \n",
       "2   hasoc_hi_164  तुम जैसे हरामियों के लिए बस जूतों की कमी है शु...    HOF   \n",
       "3  hasoc_hi_3530  बीजेपी  आकाश विजयवर्गीय जेल से रिहा, जमानत मिल...    NOT   \n",
       "4  hasoc_hi_5206  चमकी बुखार: विधानसभा परिसर में आरजेडी का प्रदर...    NOT   \n",
       "\n",
       "  task_2 task_3                                       Cleaned Text  \n",
       "0   NONE   NONE            बगलदश क शनदर वपस भरत क 314 रन पर रक  19  \n",
       "1   PRFN    UNT  सब रड नच दखन म वयसत जस ह कई शतदत क सथ कछ हग सब...  \n",
       "2   PRFN    TIN  तम जस हरमय क लए बस जत क कम ह शकर कर अभ तमहर लच...  \n",
       "3   NONE   NONE  बजप  आकश वजयवरगय जल स रह जमनत मलन क खश म एक सम...  \n",
       "4   NONE   NONE  चमक बखर वधनसभ परसर म आरजड क परदरशन तजसव यदव नद...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "922994e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=data1.drop_duplicates('Cleaned Text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42dd94e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>task_1</th>\n",
       "      <th>task_2</th>\n",
       "      <th>task_3</th>\n",
       "      <th>Cleaned Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hasoc_hi_5556</td>\n",
       "      <td>बांग्लादेश की शानदार वापसी, भारत को 314 रन पर ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>बगलदश क शनदर वपस भरत क 314 रन पर रक  19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hasoc_hi_5648</td>\n",
       "      <td>सब रंडी नाच देखने मे व्यस्त जैसे ही कोई #शांती...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>PRFN</td>\n",
       "      <td>UNT</td>\n",
       "      <td>सब रड नच दखन म वयसत जस ह कई शतदत क सथ कछ हग सब...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hasoc_hi_164</td>\n",
       "      <td>तुम जैसे हरामियों के लिए बस जूतों की कमी है शु...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>PRFN</td>\n",
       "      <td>TIN</td>\n",
       "      <td>तम जस हरमय क लए बस जत क कम ह शकर कर अभ तमहर लच...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hasoc_hi_3530</td>\n",
       "      <td>बीजेपी  आकाश विजयवर्गीय जेल से रिहा, जमानत मिल...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>बजप  आकश वजयवरगय जल स रह जमनत मलन क खश म एक सम...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hasoc_hi_5206</td>\n",
       "      <td>चमकी बुखार: विधानसभा परिसर में आरजेडी का प्रदर...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>चमक बखर वधनसभ परसर म आरजड क परदरशन तजसव यदव नद...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4660</th>\n",
       "      <td>hasoc_hi_6606</td>\n",
       "      <td>पाकिस्तान ने हिंदुओं के ख़िलाफ़ बोलने वाले को ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>पकसतन न हदओ क खलफ बलन वल क बरखसत कय ह  कय भरत ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4661</th>\n",
       "      <td>hasoc_hi_4931</td>\n",
       "      <td>कोहली है #नेहरू नहीं जो अंग्रेजों के तलवे चाटन...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>PRFN</td>\n",
       "      <td>TIN</td>\n",
       "      <td>कहल ह नहर नह ज अगरज क तलव चटन लग  भडव सल जवहर</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4662</th>\n",
       "      <td>hasoc_hi_1059</td>\n",
       "      <td>परशुराम? वही जिसने अपनी मां की हत्या की थीं?</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>परशरम वह जसन अपन म क हतय क थ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4663</th>\n",
       "      <td>hasoc_hi_5429</td>\n",
       "      <td>जिस देश में #कन्हैया_कुमार जैसा पढ़ा लिखा युवा...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>HATE</td>\n",
       "      <td>TIN</td>\n",
       "      <td>जस दश म कनहय_कमर जस पढ लख यव हर जए आतकवद  जत ज...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4664</th>\n",
       "      <td>hasoc_hi_1656</td>\n",
       "      <td>इनके बापों मैं भी दम नहीं जो भारत को इस्लामिक ...</td>\n",
       "      <td>HOF</td>\n",
       "      <td>HATE</td>\n",
       "      <td>TIN</td>\n",
       "      <td>इनक बप म भ दम नह ज भरत क इसलमक सटट बन सक हमर भ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4490 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            text_id                                               text task_1  \\\n",
       "0     hasoc_hi_5556  बांग्लादेश की शानदार वापसी, भारत को 314 रन पर ...    NOT   \n",
       "1     hasoc_hi_5648  सब रंडी नाच देखने मे व्यस्त जैसे ही कोई #शांती...    HOF   \n",
       "2      hasoc_hi_164  तुम जैसे हरामियों के लिए बस जूतों की कमी है शु...    HOF   \n",
       "3     hasoc_hi_3530  बीजेपी  आकाश विजयवर्गीय जेल से रिहा, जमानत मिल...    NOT   \n",
       "4     hasoc_hi_5206  चमकी बुखार: विधानसभा परिसर में आरजेडी का प्रदर...    NOT   \n",
       "...             ...                                                ...    ...   \n",
       "4660  hasoc_hi_6606  पाकिस्तान ने हिंदुओं के ख़िलाफ़ बोलने वाले को ...    NOT   \n",
       "4661  hasoc_hi_4931  कोहली है #नेहरू नहीं जो अंग्रेजों के तलवे चाटन...    HOF   \n",
       "4662  hasoc_hi_1059       परशुराम? वही जिसने अपनी मां की हत्या की थीं?    NOT   \n",
       "4663  hasoc_hi_5429  जिस देश में #कन्हैया_कुमार जैसा पढ़ा लिखा युवा...    HOF   \n",
       "4664  hasoc_hi_1656  इनके बापों मैं भी दम नहीं जो भारत को इस्लामिक ...    HOF   \n",
       "\n",
       "     task_2 task_3                                       Cleaned Text  \n",
       "0      NONE   NONE            बगलदश क शनदर वपस भरत क 314 रन पर रक  19  \n",
       "1      PRFN    UNT  सब रड नच दखन म वयसत जस ह कई शतदत क सथ कछ हग सब...  \n",
       "2      PRFN    TIN  तम जस हरमय क लए बस जत क कम ह शकर कर अभ तमहर लच...  \n",
       "3      NONE   NONE  बजप  आकश वजयवरगय जल स रह जमनत मलन क खश म एक सम...  \n",
       "4      NONE   NONE  चमक बखर वधनसभ परसर म आरजड क परदरशन तजसव यदव नद...  \n",
       "...     ...    ...                                                ...  \n",
       "4660   NONE   NONE  पकसतन न हदओ क खलफ बलन वल क बरखसत कय ह  कय भरत ...  \n",
       "4661   PRFN    TIN      कहल ह नहर नह ज अगरज क तलव चटन लग  भडव सल जवहर  \n",
       "4662   NONE   NONE                       परशरम वह जसन अपन म क हतय क थ  \n",
       "4663   HATE    TIN  जस दश म कनहय_कमर जस पढ लख यव हर जए आतकवद  जत ज...  \n",
       "4664   HATE    TIN  इनक बप म भ दम नह ज भरत क इसलमक सटट बन सक हमर भ...  \n",
       "\n",
       "[4490 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688b8ece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1829fd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['task_1'] = data1['task_1'].map({\"HOF\": 1, \"NOT\": 0})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90d9034a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>task_1</th>\n",
       "      <th>task_2</th>\n",
       "      <th>task_3</th>\n",
       "      <th>Cleaned Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hasoc_hi_5556</td>\n",
       "      <td>बांग्लादेश की शानदार वापसी, भारत को 314 रन पर ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>बगलदश क शनदर वपस भरत क 314 रन पर रक  19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hasoc_hi_5648</td>\n",
       "      <td>सब रंडी नाच देखने मे व्यस्त जैसे ही कोई #शांती...</td>\n",
       "      <td>1</td>\n",
       "      <td>PRFN</td>\n",
       "      <td>UNT</td>\n",
       "      <td>सब रड नच दखन म वयसत जस ह कई शतदत क सथ कछ हग सब...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hasoc_hi_164</td>\n",
       "      <td>तुम जैसे हरामियों के लिए बस जूतों की कमी है शु...</td>\n",
       "      <td>1</td>\n",
       "      <td>PRFN</td>\n",
       "      <td>TIN</td>\n",
       "      <td>तम जस हरमय क लए बस जत क कम ह शकर कर अभ तमहर लच...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hasoc_hi_3530</td>\n",
       "      <td>बीजेपी  आकाश विजयवर्गीय जेल से रिहा, जमानत मिल...</td>\n",
       "      <td>0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>बजप  आकश वजयवरगय जल स रह जमनत मलन क खश म एक सम...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hasoc_hi_5206</td>\n",
       "      <td>चमकी बुखार: विधानसभा परिसर में आरजेडी का प्रदर...</td>\n",
       "      <td>0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>चमक बखर वधनसभ परसर म आरजड क परदरशन तजसव यदव नद...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4660</th>\n",
       "      <td>hasoc_hi_6606</td>\n",
       "      <td>पाकिस्तान ने हिंदुओं के ख़िलाफ़ बोलने वाले को ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>पकसतन न हदओ क खलफ बलन वल क बरखसत कय ह  कय भरत ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4661</th>\n",
       "      <td>hasoc_hi_4931</td>\n",
       "      <td>कोहली है #नेहरू नहीं जो अंग्रेजों के तलवे चाटन...</td>\n",
       "      <td>1</td>\n",
       "      <td>PRFN</td>\n",
       "      <td>TIN</td>\n",
       "      <td>कहल ह नहर नह ज अगरज क तलव चटन लग  भडव सल जवहर</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4662</th>\n",
       "      <td>hasoc_hi_1059</td>\n",
       "      <td>परशुराम? वही जिसने अपनी मां की हत्या की थीं?</td>\n",
       "      <td>0</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>परशरम वह जसन अपन म क हतय क थ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4663</th>\n",
       "      <td>hasoc_hi_5429</td>\n",
       "      <td>जिस देश में #कन्हैया_कुमार जैसा पढ़ा लिखा युवा...</td>\n",
       "      <td>1</td>\n",
       "      <td>HATE</td>\n",
       "      <td>TIN</td>\n",
       "      <td>जस दश म कनहय_कमर जस पढ लख यव हर जए आतकवद  जत ज...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4664</th>\n",
       "      <td>hasoc_hi_1656</td>\n",
       "      <td>इनके बापों मैं भी दम नहीं जो भारत को इस्लामिक ...</td>\n",
       "      <td>1</td>\n",
       "      <td>HATE</td>\n",
       "      <td>TIN</td>\n",
       "      <td>इनक बप म भ दम नह ज भरत क इसलमक सटट बन सक हमर भ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4490 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            text_id                                               text  \\\n",
       "0     hasoc_hi_5556  बांग्लादेश की शानदार वापसी, भारत को 314 रन पर ...   \n",
       "1     hasoc_hi_5648  सब रंडी नाच देखने मे व्यस्त जैसे ही कोई #शांती...   \n",
       "2      hasoc_hi_164  तुम जैसे हरामियों के लिए बस जूतों की कमी है शु...   \n",
       "3     hasoc_hi_3530  बीजेपी  आकाश विजयवर्गीय जेल से रिहा, जमानत मिल...   \n",
       "4     hasoc_hi_5206  चमकी बुखार: विधानसभा परिसर में आरजेडी का प्रदर...   \n",
       "...             ...                                                ...   \n",
       "4660  hasoc_hi_6606  पाकिस्तान ने हिंदुओं के ख़िलाफ़ बोलने वाले को ...   \n",
       "4661  hasoc_hi_4931  कोहली है #नेहरू नहीं जो अंग्रेजों के तलवे चाटन...   \n",
       "4662  hasoc_hi_1059       परशुराम? वही जिसने अपनी मां की हत्या की थीं?   \n",
       "4663  hasoc_hi_5429  जिस देश में #कन्हैया_कुमार जैसा पढ़ा लिखा युवा...   \n",
       "4664  hasoc_hi_1656  इनके बापों मैं भी दम नहीं जो भारत को इस्लामिक ...   \n",
       "\n",
       "      task_1 task_2 task_3                                       Cleaned Text  \n",
       "0          0   NONE   NONE            बगलदश क शनदर वपस भरत क 314 रन पर रक  19  \n",
       "1          1   PRFN    UNT  सब रड नच दखन म वयसत जस ह कई शतदत क सथ कछ हग सब...  \n",
       "2          1   PRFN    TIN  तम जस हरमय क लए बस जत क कम ह शकर कर अभ तमहर लच...  \n",
       "3          0   NONE   NONE  बजप  आकश वजयवरगय जल स रह जमनत मलन क खश म एक सम...  \n",
       "4          0   NONE   NONE  चमक बखर वधनसभ परसर म आरजड क परदरशन तजसव यदव नद...  \n",
       "...      ...    ...    ...                                                ...  \n",
       "4660       0   NONE   NONE  पकसतन न हदओ क खलफ बलन वल क बरखसत कय ह  कय भरत ...  \n",
       "4661       1   PRFN    TIN      कहल ह नहर नह ज अगरज क तलव चटन लग  भडव सल जवहर  \n",
       "4662       0   NONE   NONE                       परशरम वह जसन अपन म क हतय क थ  \n",
       "4663       1   HATE    TIN  जस दश म कनहय_कमर जस पढ लख यव हर जए आतकवद  जत ज...  \n",
       "4664       1   HATE    TIN  इनक बप म भ दम नह ज भरत क इसलमक सटट बन सक हमर भ...  \n",
       "\n",
       "[4490 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1658f1a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2419\n",
       "0    2071\n",
       "Name: task_1, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1['task_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6ba19c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_hate_tweets = data1[data1.task_1 == 0]\n",
    "hate_tweets = data1[data1.task_1 == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8968b60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\dinesh reddy\\anaconda3\\lib\\site-packages (3.0.9)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\dinesh reddy\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc194d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'embeddings.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 54>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     51\u001b[0m         row_num \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Save the Excel file\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m \u001b[43mworkbook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43membeddings.xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\openpyxl\\workbook\\workbook.py:407\u001b[0m, in \u001b[0;36mWorkbook.save\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_only \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworksheets:\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_sheet()\n\u001b[1;32m--> 407\u001b[0m \u001b[43msave_workbook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\openpyxl\\writer\\excel.py:291\u001b[0m, in \u001b[0;36msave_workbook\u001b[1;34m(workbook, filename)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_workbook\u001b[39m(workbook, filename):\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;124;03m\"\"\"Save the given workbook on the filesystem under the name filename.\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \n\u001b[0;32m    282\u001b[0m \u001b[38;5;124;03m    :param workbook: the workbook to save\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    289\u001b[0m \n\u001b[0;32m    290\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     archive \u001b[38;5;241m=\u001b[39m \u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZIP_DEFLATED\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallowZip64\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    292\u001b[0m     writer \u001b[38;5;241m=\u001b[39m ExcelWriter(workbook, archive)\n\u001b[0;32m    293\u001b[0m     writer\u001b[38;5;241m.\u001b[39msave()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\zipfile.py:1248\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[0;32m   1246\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1248\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilemode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1249\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m   1250\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filemode \u001b[38;5;129;01min\u001b[39;00m modeDict:\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'embeddings.xlsx'"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "\n",
    "# Read the input data from the Excel file\n",
    "data = pd.read_excel('outpute.xlsx')\n",
    "\n",
    "# Get the sentences from the 'Text' column\n",
    "sentences = data['Cleaned Text'].tolist()\n",
    "\n",
    "# Prepare training data in FastText format\n",
    "with open('input.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(sentences))\n",
    "\n",
    "# Train FastText model\n",
    "model = fasttext.train_unsupervised('input.txt', model='skipgram')\n",
    "\n",
    "# Save the trained model\n",
    "model.save_model('fasttext_model.bin')\n",
    "\n",
    "# Load the trained model\n",
    "model = fasttext.load_model('fasttext_model.bin')\n",
    "\n",
    "# Function to get FastText embeddings for a sentence\n",
    "def get_sentence_embedding(sentence):\n",
    "    words = sentence.strip().split()\n",
    "    if len(words) == 0:\n",
    "        return None\n",
    "    embeddings = [model.get_word_vector(word) for word in words]\n",
    "    sentence_embedding = sum(embeddings) / len(embeddings)\n",
    "    return sentence_embedding\n",
    "# Get embeddings for each sentence in the dataset\n",
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    dataset = f.read().splitlines()\n",
    "\n",
    "embeddings = []\n",
    "for sentence in dataset:\n",
    "    embedding = get_sentence_embedding(sentence)\n",
    "    embeddings.append(embedding)\n",
    "\n",
    "# Create a new Excel workbook\n",
    "workbook = openpyxl.Workbook()\n",
    "sheet = workbook.active\n",
    "\n",
    "# Write the embeddings to the Excel file\n",
    "row_num = 1\n",
    "for row, embedding in enumerate(embeddings, start=1):\n",
    "    if embedding is not None:\n",
    "        for col, value in enumerate(embedding, start=1):\n",
    "            sheet.cell(row=row_num, column=col, value=value)\n",
    "        row_num += 1\n",
    "\n",
    "# Save the Excel file\n",
    "workbook.save('embeddings.xlsx')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ec09f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "117/117 [==============================] - 3s 17ms/step - loss: 0.6258 - accuracy: 0.6369 - val_loss: 0.4364 - val_accuracy: 0.7867\n",
      "Epoch 2/10\n",
      "117/117 [==============================] - 2s 16ms/step - loss: 0.3652 - accuracy: 0.8441 - val_loss: 0.3947 - val_accuracy: 0.8081\n",
      "Epoch 3/10\n",
      "117/117 [==============================] - 2s 16ms/step - loss: 0.2129 - accuracy: 0.9236 - val_loss: 0.4310 - val_accuracy: 0.8017\n",
      "Epoch 4/10\n",
      "117/117 [==============================] - 2s 17ms/step - loss: 0.1140 - accuracy: 0.9660 - val_loss: 0.4987 - val_accuracy: 0.7942\n",
      "Epoch 5/10\n",
      "117/117 [==============================] - 2s 16ms/step - loss: 0.0796 - accuracy: 0.9764 - val_loss: 0.5943 - val_accuracy: 0.7878\n",
      "Epoch 6/10\n",
      "117/117 [==============================] - 2s 15ms/step - loss: 0.0655 - accuracy: 0.9799 - val_loss: 0.6155 - val_accuracy: 0.7814\n",
      "Epoch 7/10\n",
      "117/117 [==============================] - 2s 14ms/step - loss: 0.0613 - accuracy: 0.9812 - val_loss: 0.6719 - val_accuracy: 0.7867\n",
      "Epoch 8/10\n",
      "117/117 [==============================] - 2s 15ms/step - loss: 0.0588 - accuracy: 0.9807 - val_loss: 0.6430 - val_accuracy: 0.7867\n",
      "Epoch 9/10\n",
      "117/117 [==============================] - 2s 16ms/step - loss: 0.0549 - accuracy: 0.9823 - val_loss: 0.6590 - val_accuracy: 0.7878\n",
      "Epoch 10/10\n",
      "117/117 [==============================] - 2s 15ms/step - loss: 0.0518 - accuracy: 0.9823 - val_loss: 0.7767 - val_accuracy: 0.7717\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.7767 - accuracy: 0.7717\n",
      "Epoch 1/10\n",
      "117/117 [==============================] - 2s 15ms/step - loss: 0.6298 - accuracy: 0.6388 - val_loss: 0.4343 - val_accuracy: 0.8124\n",
      "Epoch 2/10\n",
      "117/117 [==============================] - 2s 15ms/step - loss: 0.3616 - accuracy: 0.8483 - val_loss: 0.3831 - val_accuracy: 0.8156\n",
      "Epoch 3/10\n",
      "117/117 [==============================] - 2s 15ms/step - loss: 0.1993 - accuracy: 0.9335 - val_loss: 0.4495 - val_accuracy: 0.8039\n",
      "Epoch 4/10\n",
      "117/117 [==============================] - 2s 16ms/step - loss: 0.1057 - accuracy: 0.9660 - val_loss: 0.5309 - val_accuracy: 0.8071\n",
      "Epoch 5/10\n",
      "117/117 [==============================] - 2s 17ms/step - loss: 0.0776 - accuracy: 0.9762 - val_loss: 0.5826 - val_accuracy: 0.8135\n",
      "Epoch 6/10\n",
      "117/117 [==============================] - 2s 18ms/step - loss: 0.0594 - accuracy: 0.9812 - val_loss: 0.6706 - val_accuracy: 0.8114\n",
      "Epoch 7/10\n",
      "117/117 [==============================] - 2s 17ms/step - loss: 0.0646 - accuracy: 0.9794 - val_loss: 0.6445 - val_accuracy: 0.7996\n",
      "Epoch 8/10\n",
      "117/117 [==============================] - 2s 18ms/step - loss: 0.0573 - accuracy: 0.9815 - val_loss: 0.6868 - val_accuracy: 0.8124\n",
      "Epoch 9/10\n",
      "117/117 [==============================] - 2s 16ms/step - loss: 0.0548 - accuracy: 0.9820 - val_loss: 0.7818 - val_accuracy: 0.7814\n",
      "Epoch 10/10\n",
      "117/117 [==============================] - 2s 18ms/step - loss: 0.0555 - accuracy: 0.9818 - val_loss: 0.6935 - val_accuracy: 0.8060\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.8060\n",
      "Epoch 1/10\n",
      "117/117 [==============================] - 3s 18ms/step - loss: 0.6427 - accuracy: 0.6168 - val_loss: 0.4236 - val_accuracy: 0.8253\n",
      "Epoch 2/10\n",
      "117/117 [==============================] - 2s 17ms/step - loss: 0.3828 - accuracy: 0.8339 - val_loss: 0.3891 - val_accuracy: 0.8317\n",
      "Epoch 3/10\n",
      "117/117 [==============================] - 2s 21ms/step - loss: 0.2162 - accuracy: 0.9220 - val_loss: 0.4558 - val_accuracy: 0.8114\n",
      "Epoch 4/10\n",
      "117/117 [==============================] - 3s 22ms/step - loss: 0.1129 - accuracy: 0.9660 - val_loss: 0.5637 - val_accuracy: 0.8178\n",
      "Epoch 5/10\n",
      "117/117 [==============================] - 2s 17ms/step - loss: 0.0791 - accuracy: 0.9762 - val_loss: 0.6986 - val_accuracy: 0.7781\n",
      "Epoch 6/10\n",
      "117/117 [==============================] - 2s 18ms/step - loss: 0.0733 - accuracy: 0.9772 - val_loss: 0.6437 - val_accuracy: 0.8006\n",
      "Epoch 7/10\n",
      "117/117 [==============================] - 2s 18ms/step - loss: 0.0594 - accuracy: 0.9794 - val_loss: 0.7243 - val_accuracy: 0.7953\n",
      "Epoch 8/10\n",
      "117/117 [==============================] - 3s 22ms/step - loss: 0.0616 - accuracy: 0.9788 - val_loss: 0.7399 - val_accuracy: 0.8028\n",
      "Epoch 9/10\n",
      "117/117 [==============================] - 3s 22ms/step - loss: 0.0540 - accuracy: 0.9818 - val_loss: 0.7801 - val_accuracy: 0.7985\n",
      "Epoch 10/10\n",
      "117/117 [==============================] - 2s 18ms/step - loss: 0.0527 - accuracy: 0.9815 - val_loss: 0.7786 - val_accuracy: 0.7889\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.7786 - accuracy: 0.7889\n",
      "Epoch 1/10\n",
      "117/117 [==============================] - 3s 20ms/step - loss: 0.6352 - accuracy: 0.6243 - val_loss: 0.4470 - val_accuracy: 0.7921\n",
      "Epoch 2/10\n",
      "117/117 [==============================] - 3s 22ms/step - loss: 0.3666 - accuracy: 0.8459 - val_loss: 0.4109 - val_accuracy: 0.8124\n",
      "Epoch 3/10\n",
      "117/117 [==============================] - 2s 20ms/step - loss: 0.2011 - accuracy: 0.9327 - val_loss: 0.4549 - val_accuracy: 0.8146\n",
      "Epoch 4/10\n",
      "117/117 [==============================] - 2s 19ms/step - loss: 0.1097 - accuracy: 0.9644 - val_loss: 0.5534 - val_accuracy: 0.7867\n",
      "Epoch 5/10\n",
      "117/117 [==============================] - 3s 24ms/step - loss: 0.0751 - accuracy: 0.9775 - val_loss: 0.6287 - val_accuracy: 0.7953\n",
      "Epoch 6/10\n",
      "117/117 [==============================] - 3s 26ms/step - loss: 0.0679 - accuracy: 0.9794 - val_loss: 0.6627 - val_accuracy: 0.8017\n",
      "Epoch 7/10\n",
      "117/117 [==============================] - 3s 26ms/step - loss: 0.0643 - accuracy: 0.9818 - val_loss: 0.6520 - val_accuracy: 0.7964\n",
      "Epoch 8/10\n",
      "117/117 [==============================] - 3s 25ms/step - loss: 0.0563 - accuracy: 0.9820 - val_loss: 0.6921 - val_accuracy: 0.7942\n",
      "Epoch 9/10\n",
      "117/117 [==============================] - 3s 23ms/step - loss: 0.0500 - accuracy: 0.9831 - val_loss: 0.7508 - val_accuracy: 0.8092\n",
      "Epoch 10/10\n",
      "117/117 [==============================] - 3s 23ms/step - loss: 0.0551 - accuracy: 0.9815 - val_loss: 0.7330 - val_accuracy: 0.7974\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7330 - accuracy: 0.7974\n",
      "Epoch 1/10\n",
      "117/117 [==============================] - 10s 74ms/step - loss: 0.6487 - accuracy: 0.6246 - val_loss: 0.5074 - val_accuracy: 0.7513\n",
      "Epoch 2/10\n",
      "117/117 [==============================] - 3s 24ms/step - loss: 0.3766 - accuracy: 0.8384 - val_loss: 0.4208 - val_accuracy: 0.8028\n",
      "Epoch 3/10\n",
      "117/117 [==============================] - 3s 25ms/step - loss: 0.2223 - accuracy: 0.9234 - val_loss: 0.4888 - val_accuracy: 0.7889\n",
      "Epoch 4/10\n",
      "117/117 [==============================] - 3s 28ms/step - loss: 0.1317 - accuracy: 0.9585 - val_loss: 0.5693 - val_accuracy: 0.7974\n",
      "Epoch 5/10\n",
      "117/117 [==============================] - 3s 25ms/step - loss: 0.0927 - accuracy: 0.9724 - val_loss: 0.6391 - val_accuracy: 0.7964\n",
      "Epoch 6/10\n",
      "117/117 [==============================] - 3s 25ms/step - loss: 0.0688 - accuracy: 0.9775 - val_loss: 0.7600 - val_accuracy: 0.7921\n",
      "Epoch 7/10\n",
      "117/117 [==============================] - 3s 26ms/step - loss: 0.0634 - accuracy: 0.9807 - val_loss: 0.7961 - val_accuracy: 0.7942\n",
      "Epoch 8/10\n",
      "117/117 [==============================] - 3s 25ms/step - loss: 0.0589 - accuracy: 0.9804 - val_loss: 0.7926 - val_accuracy: 0.7985\n",
      "Epoch 9/10\n",
      "117/117 [==============================] - 3s 22ms/step - loss: 0.0516 - accuracy: 0.9815 - val_loss: 0.8247 - val_accuracy: 0.7964\n",
      "Epoch 10/10\n",
      "117/117 [==============================] - 2s 21ms/step - loss: 0.0530 - accuracy: 0.9815 - val_loss: 0.8485 - val_accuracy: 0.7910\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8485 - accuracy: 0.7910\n",
      "Mean Accuracy: 0.790996789932251\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# Load embeddings from Excel file\n",
    "embeddings_file = 'embeddings.xlsx'\n",
    "embeddings_df = pd.read_excel(embeddings_file, header=None)\n",
    "embeddings_matrix = embeddings_df.values\n",
    "\n",
    "# Load dataset and labels\n",
    "dataset_file = 'outpute.xlsx'\n",
    "dataset = pd.read_excel(dataset_file)\n",
    "texts = dataset['Cleaned Text'].tolist()\n",
    "labels = dataset['task_1'].tolist()\n",
    "\n",
    "# Tokenize and pad sequences\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "word_index = tokenizer.word_index\n",
    "max_sequence_length = max(len(seq) for seq in sequences)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)\n",
    "\n",
    "# Convert labels to binary format\n",
    "labels = np.array([1 if label == 'HOF' else 0 for label in labels])\n",
    "\n",
    "# Define the model architecture\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=num_words, output_dim=embedding_dim, input_length=max_sequence_length))\n",
    "    model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Perform cross-validation\n",
    "num_folds = 5\n",
    "skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "scores = []\n",
    "\n",
    "for train_index, test_index in skf.split(padded_sequences, labels):\n",
    "    x_train, x_test = padded_sequences[train_index], padded_sequences[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "    num_words = len(tokenizer.word_index) + 1\n",
    "    embedding_dim = 100\n",
    "    \n",
    "    model = create_model()\n",
    "    model.fit(x_train, y_train, batch_size=32, epochs=10, validation_data=(x_test, y_test))\n",
    "    \n",
    "    _, accuracy = model.evaluate(x_test, y_test)\n",
    "    scores.append(accuracy)\n",
    "    \n",
    "# Calculate and print the mean accuracy\n",
    "mean_accuracy = np.mean(scores)\n",
    "print(f\"Mean Accuracy: {mean_accuracy}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4943ce68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "117/117 [==============================] - 3s 21ms/step - loss: 0.5656 - accuracy: 0.7353 - val_loss: 0.4399 - val_accuracy: 0.8049\n",
      "Epoch 2/10\n",
      "117/117 [==============================] - 2s 21ms/step - loss: 0.2825 - accuracy: 0.8995 - val_loss: 0.2505 - val_accuracy: 0.9100\n",
      "Epoch 3/10\n",
      "117/117 [==============================] - 2s 19ms/step - loss: 0.1425 - accuracy: 0.9507 - val_loss: 0.3027 - val_accuracy: 0.8917\n",
      "Epoch 4/10\n",
      "117/117 [==============================] - 2s 17ms/step - loss: 0.0664 - accuracy: 0.9823 - val_loss: 0.3528 - val_accuracy: 0.8875\n",
      "Epoch 5/10\n",
      "117/117 [==============================] - 2s 17ms/step - loss: 0.0418 - accuracy: 0.9917 - val_loss: 0.3909 - val_accuracy: 0.8939\n",
      "Epoch 6/10\n",
      "117/117 [==============================] - 2s 16ms/step - loss: 0.0304 - accuracy: 0.9933 - val_loss: 0.4604 - val_accuracy: 0.8596\n",
      "Epoch 7/10\n",
      "117/117 [==============================] - 2s 15ms/step - loss: 0.0305 - accuracy: 0.9941 - val_loss: 0.4823 - val_accuracy: 0.8864\n",
      "Epoch 8/10\n",
      "117/117 [==============================] - 2s 20ms/step - loss: 0.0281 - accuracy: 0.9938 - val_loss: 0.4918 - val_accuracy: 0.8853\n",
      "Epoch 9/10\n",
      "117/117 [==============================] - 2s 21ms/step - loss: 0.0245 - accuracy: 0.9946 - val_loss: 0.4905 - val_accuracy: 0.8821\n",
      "Epoch 10/10\n",
      "117/117 [==============================] - 2s 20ms/step - loss: 0.0249 - accuracy: 0.9949 - val_loss: 0.5212 - val_accuracy: 0.8821\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5212 - accuracy: 0.8821\n",
      "Epoch 1/10\n",
      "117/117 [==============================] - 3s 24ms/step - loss: 0.5784 - accuracy: 0.7318 - val_loss: 0.5079 - val_accuracy: 0.7353\n",
      "Epoch 2/10\n",
      "117/117 [==============================] - 2s 19ms/step - loss: 0.3303 - accuracy: 0.8682 - val_loss: 0.2573 - val_accuracy: 0.9046\n",
      "Epoch 3/10\n",
      "117/117 [==============================] - 2s 19ms/step - loss: 0.1626 - accuracy: 0.9424 - val_loss: 0.2921 - val_accuracy: 0.8971\n",
      "Epoch 4/10\n",
      "117/117 [==============================] - 2s 17ms/step - loss: 0.0853 - accuracy: 0.9729 - val_loss: 0.3503 - val_accuracy: 0.8864\n",
      "Epoch 5/10\n",
      "117/117 [==============================] - 2s 17ms/step - loss: 0.0454 - accuracy: 0.9904 - val_loss: 0.4061 - val_accuracy: 0.8896\n",
      "Epoch 6/10\n",
      "117/117 [==============================] - 2s 15ms/step - loss: 0.0321 - accuracy: 0.9936 - val_loss: 0.4309 - val_accuracy: 0.8821\n",
      "Epoch 7/10\n",
      "117/117 [==============================] - 2s 16ms/step - loss: 0.0292 - accuracy: 0.9946 - val_loss: 0.4672 - val_accuracy: 0.8907\n",
      "Epoch 8/10\n",
      "117/117 [==============================] - 2s 16ms/step - loss: 0.0260 - accuracy: 0.9949 - val_loss: 0.4861 - val_accuracy: 0.8885\n",
      "Epoch 9/10\n",
      "117/117 [==============================] - 2s 15ms/step - loss: 0.0236 - accuracy: 0.9954 - val_loss: 0.5347 - val_accuracy: 0.8907\n",
      "Epoch 10/10\n",
      "117/117 [==============================] - 2s 17ms/step - loss: 0.0236 - accuracy: 0.9952 - val_loss: 0.5162 - val_accuracy: 0.8778\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.8778\n",
      "Epoch 1/10\n",
      "117/117 [==============================] - 3s 19ms/step - loss: 0.5636 - accuracy: 0.7320 - val_loss: 0.4208 - val_accuracy: 0.8317\n",
      "Epoch 2/10\n",
      "117/117 [==============================] - 2s 19ms/step - loss: 0.2811 - accuracy: 0.9051 - val_loss: 0.2839 - val_accuracy: 0.8982\n",
      "Epoch 3/10\n",
      "117/117 [==============================] - 2s 21ms/step - loss: 0.1550 - accuracy: 0.9453 - val_loss: 0.3164 - val_accuracy: 0.8928\n",
      "Epoch 4/10\n",
      "117/117 [==============================] - 3s 21ms/step - loss: 0.0764 - accuracy: 0.9807 - val_loss: 0.3711 - val_accuracy: 0.8907\n",
      "Epoch 5/10\n",
      "117/117 [==============================] - 3s 23ms/step - loss: 0.0475 - accuracy: 0.9882 - val_loss: 0.4376 - val_accuracy: 0.8842\n",
      "Epoch 6/10\n",
      "117/117 [==============================] - 2s 21ms/step - loss: 0.0448 - accuracy: 0.9922 - val_loss: 0.4753 - val_accuracy: 0.8917\n",
      "Epoch 7/10\n",
      "117/117 [==============================] - 2s 17ms/step - loss: 0.0313 - accuracy: 0.9936 - val_loss: 0.5387 - val_accuracy: 0.8928\n",
      "Epoch 8/10\n",
      "117/117 [==============================] - 2s 21ms/step - loss: 0.0305 - accuracy: 0.9928 - val_loss: 0.4851 - val_accuracy: 0.8842\n",
      "Epoch 9/10\n",
      "117/117 [==============================] - 3s 22ms/step - loss: 0.0259 - accuracy: 0.9952 - val_loss: 0.5320 - val_accuracy: 0.8885\n",
      "Epoch 10/10\n",
      "117/117 [==============================] - 3s 25ms/step - loss: 0.0234 - accuracy: 0.9952 - val_loss: 0.5154 - val_accuracy: 0.8842\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.8842\n",
      "Epoch 1/10\n",
      "117/117 [==============================] - 3s 19ms/step - loss: 0.5524 - accuracy: 0.7414 - val_loss: 0.3975 - val_accuracy: 0.8296\n",
      "Epoch 2/10\n",
      "117/117 [==============================] - 2s 20ms/step - loss: 0.2600 - accuracy: 0.9078 - val_loss: 0.3042 - val_accuracy: 0.8842\n",
      "Epoch 3/10\n",
      "117/117 [==============================] - 2s 20ms/step - loss: 0.1384 - accuracy: 0.9536 - val_loss: 0.3564 - val_accuracy: 0.8778\n",
      "Epoch 4/10\n",
      "117/117 [==============================] - 2s 21ms/step - loss: 0.0727 - accuracy: 0.9786 - val_loss: 0.4377 - val_accuracy: 0.8617\n",
      "Epoch 5/10\n",
      "117/117 [==============================] - 2s 18ms/step - loss: 0.0435 - accuracy: 0.9893 - val_loss: 0.5046 - val_accuracy: 0.8617\n",
      "Epoch 6/10\n",
      "117/117 [==============================] - 2s 20ms/step - loss: 0.0371 - accuracy: 0.9922 - val_loss: 0.5321 - val_accuracy: 0.8650\n",
      "Epoch 7/10\n",
      "117/117 [==============================] - 3s 23ms/step - loss: 0.0309 - accuracy: 0.9930 - val_loss: 0.5855 - val_accuracy: 0.8628\n",
      "Epoch 8/10\n",
      "117/117 [==============================] - 2s 20ms/step - loss: 0.0303 - accuracy: 0.9933 - val_loss: 0.5904 - val_accuracy: 0.8671\n",
      "Epoch 9/10\n",
      "117/117 [==============================] - 2s 16ms/step - loss: 0.0226 - accuracy: 0.9946 - val_loss: 0.6396 - val_accuracy: 0.8628\n",
      "Epoch 10/10\n",
      "117/117 [==============================] - 2s 18ms/step - loss: 0.0282 - accuracy: 0.9946 - val_loss: 0.6455 - val_accuracy: 0.8617\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6455 - accuracy: 0.8617\n",
      "Epoch 1/10\n",
      "117/117 [==============================] - 3s 24ms/step - loss: 0.5669 - accuracy: 0.7291 - val_loss: 0.4586 - val_accuracy: 0.7513\n",
      "Epoch 2/10\n",
      "117/117 [==============================] - 2s 19ms/step - loss: 0.2892 - accuracy: 0.8848 - val_loss: 0.2764 - val_accuracy: 0.9068\n",
      "Epoch 3/10\n",
      "117/117 [==============================] - 2s 16ms/step - loss: 0.1543 - accuracy: 0.9419 - val_loss: 0.3228 - val_accuracy: 0.8960\n",
      "Epoch 4/10\n",
      "117/117 [==============================] - 2s 16ms/step - loss: 0.0785 - accuracy: 0.9770 - val_loss: 0.4157 - val_accuracy: 0.8896\n",
      "Epoch 5/10\n",
      "117/117 [==============================] - 2s 16ms/step - loss: 0.0517 - accuracy: 0.9863 - val_loss: 0.4792 - val_accuracy: 0.9003\n",
      "Epoch 6/10\n",
      "117/117 [==============================] - 2s 18ms/step - loss: 0.0388 - accuracy: 0.9917 - val_loss: 0.4932 - val_accuracy: 0.8971\n",
      "Epoch 7/10\n",
      "117/117 [==============================] - 2s 18ms/step - loss: 0.0357 - accuracy: 0.9925 - val_loss: 0.5018 - val_accuracy: 0.8810\n",
      "Epoch 8/10\n",
      "117/117 [==============================] - 2s 17ms/step - loss: 0.0328 - accuracy: 0.9933 - val_loss: 0.5162 - val_accuracy: 0.8853\n",
      "Epoch 9/10\n",
      "117/117 [==============================] - 2s 18ms/step - loss: 0.0272 - accuracy: 0.9941 - val_loss: 0.4955 - val_accuracy: 0.8992\n",
      "Epoch 10/10\n",
      "117/117 [==============================] - 2s 19ms/step - loss: 0.0254 - accuracy: 0.9949 - val_loss: 0.5207 - val_accuracy: 0.8650\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5207 - accuracy: 0.8650\n",
      "Mean Accuracy: 0.8741693615913391\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# Load embeddings from Excel file\n",
    "embeddings_file = 'embeddings.xlsx'\n",
    "embeddings_df = pd.read_excel(embeddings_file, header=None)\n",
    "embeddings_matrix = embeddings_df.values\n",
    "\n",
    "# Load dataset and labels\n",
    "dataset_file = 'outpute.xlsx'\n",
    "dataset = pd.read_excel(dataset_file)\n",
    "texts = dataset['Cleaned Text'].tolist()\n",
    "labels = dataset['task_2'].tolist()\n",
    "\n",
    "# Tokenize and pad sequences\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "word_index = tokenizer.word_index\n",
    "max_sequence_length = max(len(seq) for seq in sequences)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)\n",
    "\n",
    "# Convert labels to binary format\n",
    "labels = np.array([1 if label == 'PRFN' else 0 for label in labels])\n",
    "\n",
    "# Define the model architecture\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=num_words, output_dim=embedding_dim, input_length=max_sequence_length))\n",
    "    model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))  # Change output dimension to 2 and activation to softmax\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])  # Use sparse categorical crossentropy for multi-class classification\n",
    "    return model\n",
    "\n",
    "# Perform cross-validation\n",
    "num_folds = 5\n",
    "skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "scores = []\n",
    "\n",
    "for train_index, test_index in skf.split(padded_sequences, labels):\n",
    "    x_train, x_test = padded_sequences[train_index], padded_sequences[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "    num_words = len(tokenizer.word_index) + 1\n",
    "    embedding_dim = 100\n",
    "    \n",
    "    model = create_model()\n",
    "    model.fit(x_train, y_train, batch_size=32, epochs=10, validation_data=(x_test, y_test))\n",
    "    \n",
    "    _, accuracy = model.evaluate(x_test, y_test)\n",
    "    scores.append(accuracy)\n",
    "    \n",
    "# Calculate and print the mean accuracy\n",
    "mean_accuracy = np.mean(scores)\n",
    "print(f\"Mean Accuracy: {mean_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1aac4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#using LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c376e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dinesh Reddy\\AppData\\Local\\Temp\\ipykernel_25360\\2098938853.py:19: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if word in embeddings_matrix:\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# Load embeddings from Excel file\n",
    "embeddings_file = 'embeddings.xlsx'\n",
    "embeddings_df = pd.read_excel(embeddings_file, header=None)\n",
    "embeddings_matrix = embeddings_df.values\n",
    "\n",
    "# Load tokenizer and word index\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Create a new embeddings matrix with the correct vocabulary\n",
    "num_words = len(word_index) + 1\n",
    "embedding_dim = embeddings_matrix.shape[1]\n",
    "new_embeddings_matrix = np.zeros((num_words, embedding_dim))\n",
    "for word, index in word_index.items():\n",
    "    if word in embeddings_matrix:\n",
    "        new_embeddings_matrix[index] = embeddings_matrix[embeddings_matrix[word]]\n",
    "\n",
    "# Use the new embeddings matrix in the model\n",
    "model.add(Embedding(input_dim=num_words, output_dim=embedding_dim, input_length=max_sequence_length, weights=[new_embeddings_matrix], trainable=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0e6042",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3df0b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
